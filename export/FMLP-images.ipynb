{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "import ffmpegio\n",
    "from data import datasets\n",
    "gpu = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment(results_dir, model):\n",
    "    param = torch.load(os.path.join(results_dir, \"param.pth\"))\n",
    "    spec = importlib.util.spec_from_file_location(\"module.name\", os.path.abspath(os.path.join(results_dir, os.path.basename(param.experiment.script_file_path))))\n",
    "    experiment_script = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[\"module.name\"] = experiment_script\n",
    "    spec.loader.exec_module(experiment_script)\n",
    "    exp = experiment_script.load_experiment(results_dir, model, gpu=gpu)\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nr = 10\n",
    "results_dir = \"results/10/FMLP/validation/900/s_t 1.0 spatial_coordinate_scale 30.0/\"\n",
    "model = \"training/ser_highscore.pth\"\n",
    "exp = load_experiment(results_dir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_mp4(imgs, export_dir, frame_times):\n",
    "    create_dir(export_dir)\n",
    "\n",
    "    imgs_rgb = imgs.copy()\n",
    "    img_max_val = datasets[dataset_nr][\"brightness\"]\n",
    "\n",
    "    imgs_rgb /= img_max_val\n",
    "    imgs_rgb[imgs_rgb > 1.] = 1. # clip maximum\n",
    "    imgs_rgb[imgs_rgb < 0] = 0. # clip minimum (should not be necessary for absolute valued images)\n",
    "    imgs_rgb *= 255\n",
    "    imgs_rgb = np.uint8(imgs_rgb)\n",
    "\n",
    "    imgs_rgb = np.expand_dims(imgs_rgb, axis=3)\n",
    "    imgs_rgb = imgs_rgb.repeat(3, axis=3)\n",
    "\n",
    "    raw_video_file = os.path.join(export_dir, '30fps_cfr.mp4')\n",
    "\n",
    "    ffmpegio.video.write(raw_video_file, 30, imgs_rgb, overwrite=True)\n",
    "\n",
    "    # write timecode file\n",
    "\n",
    "    timecode = \"\"\"# timecode format v2\n",
    "\n",
    "    \"\"\"\n",
    "    for i, t_k in enumerate(frame_times):\n",
    "        if i >= len(imgs): break\n",
    "        timecode += \"{}\\n\".format(t_k * 1000)\n",
    "\n",
    "    timecodes_file = os.path.join(export_dir, 'timecodes.txt')\n",
    "    with open(timecodes_file, 'w') as f:\n",
    "        f.write(timecode)\n",
    "\n",
    "    timecoded_vfr_file = os.path.join(export_dir, 'timecoded_vfr.mp4')\n",
    "    timecoded_cfr_file = os.path.join(export_dir, 'timecoded_cfr.mp4')\n",
    "\n",
    "\n",
    "    os.system(\"mp4fpsmod -o \\\"{}\\\" -t \\\"{}\\\" \\\"{}\\\"\".format(timecoded_vfr_file, timecodes_file, raw_video_file))\n",
    "    os.system(\"ffmpeg -y -i \\\"{}\\\" \\\"{}\\\"\".format(timecoded_vfr_file, timecoded_cfr_file))\n",
    "\n",
    "\n",
    "if dataset_nr == 10 or dataset_nr == 15:\n",
    "    imgs = np.stack([np.rot90(exp.model.evaluate_npy(sample)[26:-26,65:-65]) for sample in exp.dataset])\n",
    "else:\n",
    "    imgs = np.stack([np.rot90(exp.model.evaluate_npy(sample)[47:-47,120:-120]) for sample in exp.dataset])\n",
    "\n",
    "export_dir = \"media/lowres_highsnr/FMLP/900/\"\n",
    "render_mp4(imgs, export_dir, exp.param.data.frame_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "\n",
    "images = [exp.model.evaluate_npy(exp.dataset[k]) for k in [105, 115, 125, 135]]\n",
    "if dataset_nr == 10 or dataset_nr == 15: # low-res\n",
    "    images = [np.rot90(img[26:-26,65:-65]) for img in images]\n",
    "else: # high-res\n",
    "    images = [np.rot90(img[47:-47,120:-120]) for img in images]\n",
    "all_images.append(images)\n",
    "\n",
    "import glob, tikzplotlib\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(9, 9))\n",
    "brightness = datasets[dataset_nr][\"brightness\"]\n",
    "for i, img in enumerate(images):\n",
    "    axes[i].imshow(img, cmap=\"gray\", vmax=brightness, vmin=0)\n",
    "\n",
    "create_dir(os.path.join(results_dir, \"figures\"))\n",
    "tex_file_name = os.path.join(results_dir, \"figures/fmlp.tex\")\n",
    "for file in glob.glob(os.path.splitext(tex_file_name)[0] + \"-*\"):\n",
    "    os.remove(file)\n",
    "tikzplotlib.save(tex_file_name, standalone=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
