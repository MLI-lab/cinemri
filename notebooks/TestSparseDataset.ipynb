{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "from data.scanner.CAVA_V1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseCartesianDataset():\n",
    "    \"\"\" \n",
    "    This class stores a Cartesian dataset without zeros in the k-space and stores a tensor of measured k-space coordinates (trajectory) instead of a sampling mask. \n",
    "    \n",
    "    attributes:\n",
    "    - `kspace`: shape (Nl, Nc, Nr, 2) contains the complex k-space measurements (real, imaginary part in last dimension)\n",
    "    - `trajectory`: shape (Nl, Nr, 3) contains the k-space coordinates of the measurements normalized to 1/FOV. Order of the dimensions: z y x.\n",
    "    - `mask`: shape (Nl, Nr, 3) contains the indices of the measured coordinates on the Cartesian grid (same information as in trajectory, but in a more accessible format). Order of the dimensions: z y x.\n",
    "    - `smaps`:  shape (Nc, Nz, Ny, Nx, 2) torch.tensor float32\n",
    "    - `transform`: optional function: dict -> dict\n",
    "    - `additional_data`: arbitrary data\n",
    "\n",
    "    naming:\n",
    "    - `Nk`: number of frames\n",
    "    - `Nl`: number of measured k-space lines\n",
    "    - `Nr`: number if measurements in the read-out direction (x-direction)\n",
    "    - `Nc`: number of receiver coils\n",
    "    - `Nz`, `Ny`, `Nx`: resolution in z, y, and x-direction\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kspace, trajectory, mask, line_indices, smaps, reference=None, transform=None, additional_data=None):\n",
    "        \n",
    "        self.kspace = kspace # shape (Nk, Nc, Nl, Nr, 2) torch.tensor float32\n",
    "        self.trajectory = trajectory # shape (Nk, Nl, Nr, 3) torch.tensor float32\n",
    "        self.mask = mask # shape (Nk, Nl, Nr, 3) LongTensor\n",
    "        self.line_indices = line_indices # shape (Nk, Nl) LongTensor\n",
    "        self.smaps = smaps # shape (Nc, Nz, Ny, Nx) torch.tensor float32\n",
    "        self.transform = transform # function: transform(dict: sample) -> dict\n",
    "        self.reference = reference\n",
    "        self.additional_data = additional_data # arbitrary data \n",
    "\n",
    "        assert kspace.ndim == 5\n",
    "        assert trajectory.ndim == 4\n",
    "        assert mask.ndim == 4\n",
    "        assert line_indices.ndim == 2\n",
    "        assert smaps.ndim == 4\n",
    "        assert kspace.shape[-1] == 2\n",
    "        assert trajectory.shape[-1] == 3\n",
    "        assert mask.shape[-1] == 3\n",
    "\n",
    "        self.Nk, self.Nc, self.Nl, self.Nr, _ = kspace.shape\n",
    "        _, self.Nz, self.Ny, self.Nx = smaps.shape\n",
    "                \n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_sparse_matfile2d_extract_validation_dataset_rebin(self, matfile_path, listfile_path,\n",
    "                                                         transform=None,\n",
    "                                                         shift=False,\n",
    "                                                         remove_padding=False,\n",
    "                                                         set_smaps_outside_to_one=False,\n",
    "                                                         validation_percentage=0.,\n",
    "                                                         number_of_lines_per_frame=6,\n",
    "                                                         max_Nk=-1,\n",
    "                                                         seed=1998\n",
    "                                                         ):\n",
    "        \"\"\" \n",
    "        Loads `mat_file_path` that stores measurement data without zeros in the k-space (sparse respresentation of data).\n",
    "        Requires `listfile_path` that contains information about the order and position of the measured k-space lines.\n",
    "        Randomly extracts `validation_percentage` percent of the k-space lines for validation.\n",
    "        Bins the remaining lines into frames with `number_of_lines_per_frame` lines each. If `max_Nk` is specified, the number of frames is reduced and excess frames are discarded.\n",
    "\n",
    "\n",
    "        Arguments:\n",
    "        - `transform`: An optional function that is applied to every sample data loaded from the dataset with the get_item() method.\n",
    "        - `shift`: If true, the image is shifted by Ny/4. This is necessary if the k-space data does not match the smaps otherwise.\n",
    "        - `remove_padding`: By default, the k-space data of the scanner is zero-padded and the smaps are computed on a larger grid. If `remove_padding` is true, the padding is removed and the smaps are cropped in the Fourier domain.\n",
    "        - `set_smaps_outside_to_one`: By default, the smaps estimated by the scanner have zero entries outside the human body (they cannot be estimated outside, as there is no signal). Thus, the reconstructions can take arbitrary values outside the body without affecting the reconstruction loss. If `set_smaps_outside_to_one` is true, the zero-sensitivities are set to 1.0. By setting the smaps outside to 1.0, the reconstructions are forced to zero outside the human body.\n",
    "        - `validation_percentage`: Percentage of the k-space lines that are used for validation. Default: 0.\n",
    "        - `number_of_lines_per_frame`: Number of k-space lines per frame. Default: 6.\n",
    "        - `max_Nk`: If not -1, the number of frames is limited.\n",
    "        - `seed`: seed for the random extraction of k-space lines.\n",
    "        \"\"\"\n",
    "\n",
    "        # save the current state of the RNG and set the new one\n",
    "        random_state = np.random.get_state() \n",
    "        np.random.seed(seed) \n",
    "\n",
    "        list_data = ListData(file_name=listfile_path)\n",
    "\n",
    "        # detect datasets that are binned by cardiac phases -> handle them separately as they probably use the SENSE pattern\n",
    "        assert list_data.Nk_card == 1, \"ECG-binned data needs to be loaded differently (Nk_card > 1, Nk == 1). Not implemented yet for sparse datasets.\"\n",
    "        \n",
    "        # load matrices from the .mat file\n",
    "        with h5py.File(matfile_path, 'r', rdcc_nbytes=1024**3, rdcc_w0=1, rdcc_nslots=1024) as f:\n",
    "            raw_smaps = h5py2Complex(f[\"smaps\"], load_in_chunks=False)\n",
    "            raw_kspace = h5py2Complex(f[\"kspace\"], load_in_chunks=False)\n",
    "            reference = np.array(f[\"reference\"])\n",
    "            encoding_pars = parse_struct(f[\"encoding_pars\"])\n",
    "\n",
    "        # if required, set the zero pixels of the smaps (outside the body) to 1.0\n",
    "        if set_smaps_outside_to_one:\n",
    "            raw_smaps[raw_smaps == 0.] = 1.\n",
    "\n",
    "        # if required, remove the zero-padding from the k-space and truncate the smaps in the Fourier domain\n",
    "        if remove_padding: # remove the padding\n",
    "\n",
    "            # compute the resolution in x-direction without padding\n",
    "            Nx = int(encoding_pars[\"KxRange\"][1] - encoding_pars[\"KxRange\"][0] + 1)\n",
    "            Nc, Nyold, Nxold = raw_smaps.shape\n",
    "\n",
    "            # compute the resolution in y-direction without padding\n",
    "            if -encoding_pars[\"KyRange\"][0] == encoding_pars[\"KyRange\"][1] + 1: # standard case\n",
    "                Ny = int(encoding_pars[\"KyRange\"][1] - encoding_pars[\"KyRange\"][0] + 1)\n",
    "            elif -encoding_pars[\"KyRange\"][0] < encoding_pars[\"KyRange\"][1]: # probably partial-Fourier\n",
    "                Ny = int(2 * encoding_pars[\"KyRange\"][1])\n",
    "            else: # unknown case\n",
    "                print(encoding_pars[\"KyRange\"], raw_smaps.shape[2])\n",
    "                raise Exception\n",
    "\n",
    "            # truncate the smaps in the Fourier domain\n",
    "            Nystart, Nxstart = int((Nyold - Ny) / 2), int((Nxold - Nx) / 2)\n",
    "\n",
    "            smaps = to_tensor(raw_smaps)\n",
    "            smaps_fft = fft2(smaps)\n",
    "            smaps_fft = smaps_fft[:,Nystart:(Nystart+Ny), Nxstart:(Nxstart+Nx), :]\n",
    "            smaps = ifft2(smaps_fft)\n",
    "\n",
    "        else: # keep the padding\n",
    "            Nc, Ny, Nx = raw_smaps.shape\n",
    "            smaps = to_tensor(raw_smaps)\n",
    "            \n",
    "        # get a lists that contains the following information for every ky-line in the matrix `kspace`: index of the dynamic, index of the coil, ky indices (shifted)\n",
    "        dynamics, coil_indices, ky_indices = list_data.get_dynamics_channel_indices_and_kyindices()\n",
    "        num_lines_all_coils, Nr = raw_kspace.shape\n",
    "        assert num_lines_all_coils % Nc == 0\n",
    "        Nl = num_lines_all_coils // Nc\n",
    "        \n",
    "        # generate a random subset of measured lines:\n",
    "        validation_indices = np.arange(stop=Nl)\n",
    "        np.random.shuffle(validation_indices)\n",
    "        validation_indices = validation_indices[0:int(Nl * validation_percentage / 100)]\n",
    "\n",
    "        Nk = (Nl - len(validation_indices)) // number_of_lines_per_frame\n",
    "        if max_Nk != -1:\n",
    "            Nk = min(Nk, max_Nk)\n",
    "\n",
    "        # create matrices where the sparse data is filled into\n",
    "        kspace = np.zeros((Nk, Nc, number_of_lines_per_frame, Nr), dtype=np.csingle)\n",
    "        mask = np.zeros((Nk, number_of_lines_per_frame, Nr, 3), dtype=np.int64)\n",
    "        trajectory = np.zeros((Nk, number_of_lines_per_frame, Nr, 3), dtype=np.float32)\n",
    "        line_indices = np.zeros((Nk, number_of_lines_per_frame), dtype=np.int64)\n",
    "\n",
    "        # find the zero index of the k-space matrix in ky-direction\n",
    "        ky_zero_index = int(Ny / 2)\n",
    "        # find the first kx index that should be filled with data\n",
    "        kx_shift = int(Nx / 2 - Nr / 2)\n",
    "\n",
    "        # stacks the measurements from different coils\n",
    "        def line_generator():\n",
    "\n",
    "            for l in range(Nl):\n",
    "\n",
    "                line_kspace = np.zeros((Nc, Nr), dtype=np.csingle)\n",
    "                for c in range(Nc):\n",
    "                    i = l*Nc+c\n",
    "                    assert dynamics[i] == dynamics[l*Nc]\n",
    "                    assert ky_indices[i] == ky_indices[l*Nc]\n",
    "                    line_kspace[coil_indices[i], :] = raw_kspace[i, :]\n",
    "\n",
    "                ky = ky_indices[l*Nc]\n",
    "                ky_index = ky_zero_index + ky\n",
    "                ky_coordinate = np.pi * ky / Ny\n",
    "\n",
    "                if shift:\n",
    "                    line_kspace *= np.exp(np.pi*1j*(ky_index - Ny/2))\n",
    "\n",
    "                kx_indices = kx_shift + np.arange(Nr)\n",
    "                kx_coordinates = np.pi * (-int(Nr/2) + np.arange(Nr)) / Nx\n",
    "\n",
    "                line_mask = np.stack((np.zeros(Nr), np.ones(Nr)*ky_index, kx_indices), axis=-1)\n",
    "                line_trajectory = np.stack((np.zeros(Nr), np.ones(Nr)*ky_coordinate, kx_coordinates), axis=-1)\n",
    "\n",
    "                yield line_kspace, line_trajectory, line_mask\n",
    "\n",
    "\n",
    "        lines = line_generator()\n",
    "        j = 0\n",
    "        validation_dataset = []\n",
    "        for k in range(Nk):\n",
    "            for l in range(number_of_lines_per_frame):\n",
    "                while j in validation_indices: # put lines in the validation dataset\n",
    "                    line_kspace, line_trajectory, line_mask = next(lines)\n",
    "                    validation_dataset.append({\n",
    "                        \"line_index\": j,\n",
    "                        \"k\": k,\n",
    "                        \"kspace\": to_tensor(line_kspace),\n",
    "                        \"trajectory\": to_tensor(line_trajectory),\n",
    "                        \"mask\": to_tensor(line_mask)\n",
    "                    })\n",
    "                    j += 1\n",
    "                \n",
    "                # put the line in the training dataset\n",
    "                line_kspace, line_trajectory, line_mask = next(lines)\n",
    "                kspace[k, :, l, :] = line_kspace\n",
    "                trajectory[k, l, :, :] = line_trajectory\n",
    "                mask[k, l, :, :] = line_mask\n",
    "                line_indices[k, l] = j\n",
    "\n",
    "                j += 1\n",
    "\n",
    "        \n",
    "        # insert dimensions for the z-axis (that is not used since this method handles 2D datasets with a single slice)\n",
    "        kspace = to_tensor(kspace)\n",
    "        trajectory = to_tensor(trajectory)\n",
    "        mask = to_tensor(mask)\n",
    "        \n",
    "        # if reference data is available, the reference matrix has at least 3 dimensions\n",
    "        if reference.ndim < 3:\n",
    "            reference = None\n",
    "        if reference is not None: reference = to_tensor(np.expand_dims(reference, axis=1))\n",
    "\n",
    "        # restore the state of the RNG\n",
    "        np.random.set_state(random_state)\n",
    "\n",
    "        return self(kspace, trajectory, mask, line_indices, smaps, reference=reference, transform=transform), validation_dataset\n",
    "    \n",
    "    @classmethod\n",
    "    def from_sparse_cartesian_dataset(self, dataset, transform=None):\n",
    "        \"\"\"\n",
    "        Creates a shallow copy (underlying data remains identical).\n",
    "        \n",
    "        Use this method to initialize many different subclasses from the same data, without loading the data into memory multiple times.\n",
    "        \"\"\"\n",
    "        return self(dataset.kspace, dataset.trajectory, dataset.mask, dataset.line_indices, dataset.smaps, reference=dataset.reference, additional_data=dataset.additional_data, transform=transform)\n",
    "\n",
    "    def shape(self):\n",
    "        \"\"\"\n",
    "        Returns (Nk, Nc, Nz, Ny, Nx).\n",
    "        \"\"\"\n",
    "        return (self.Nk, self.Nc, self.Nz, self.Ny, self.Nx)\n",
    "        \n",
    "    def subset(self, subset_indices):\n",
    "        return Subset(self, subset_indices)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Nk\n",
    "\n",
    "    def __getitem__(self, k):        \n",
    "\n",
    "        if isinstance(k, int):\n",
    "            indices = [k]\n",
    "        elif isinstance(k, slice):\n",
    "            indices = range(k.start or 0, k.stop or self.Nk, k.step or 1)\n",
    "        elif isinstance(k, Iterable):\n",
    "            indices = k\n",
    "        else:\n",
    "            raise Exception(\"invalid index format\")\n",
    "\n",
    "        reference = None\n",
    "        if not self.reference is None:\n",
    "            reference = torch.zeros((len(indices), 1, self.Ny, self.Nx), dtype=np.csingle)\n",
    "            for n, index in enumerate(indices):\n",
    "                reference[n, 0, :, :] = self.reference[index, :, :, :]\n",
    "\n",
    "        sample = {\n",
    "            'indices': indices,\n",
    "            'kspace': self.kspace[indices, :, :, :, :],\n",
    "            'trajectory': self.trajectory[indices, :, :, :],\n",
    "            'mask': self.mask[indices, :, :, :],\n",
    "            'line_indices': self.line_indices[indices, :],\n",
    "            'smaps': self.smaps,\n",
    "            'reference': reference,\n",
    "        }\n",
    "\n",
    "        if(self.transform):\n",
    "            return self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = datasets_cava_v1[10]\n",
    "dataset, validation_dataset = SparseCartesianDataset.from_sparse_matfile2d_extract_validation_dataset_rebin(dataset_info[\"matfile_path\"], dataset_info[\"listfile_path\"], remove_padding=True, validation_percentage=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7 (default, May  7 2020, 21:25:33) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
