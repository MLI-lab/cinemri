{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import *\n",
    "from data.scanner.CAVA_V1 import *\n",
    "import tikzplotlib\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "gpu = 0\n",
    "torch.cuda.set_device(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phantom image and generate fully sampled k-space data of a single frame\n",
    "ref_imgs = np.array(np.load(\"data/xcat/phantom3/filtered_imgs.npy\"), dtype=np.complex64)\n",
    "img = to_tensor(ref_imgs[0].T)\n",
    "del ref_imgs\n",
    "\n",
    "smaps = to_tensor(np.load(\"data/xcat/phantom3/low_res_as_cava_v1_10_smaps.npy\")).squeeze() # Nc Ny Nx 2\n",
    "kspace = fft2(complex_mul(img.unsqueeze(dim=0), smaps)) # Nc Ny Nx 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experimental dataset FB 10, single dynamic. Perform bart reconstruction and use as ground-truth\n",
    "dataset_info = datasets_cava_v1[10]\n",
    "dataset = CartesianSliceDataset.from_sparse_matfile2d(dataset_info[\"matfile_path\"], dataset_info[\"listfile_path\"], remove_padding=True, shift=True)\n",
    "\n",
    "img = to_tensor(bart_l1_wavelet_reconstruction(dataset[41])).squeeze()\n",
    "smaps = dataset.smaps.squeeze()\n",
    "kspace = fft2(complex_mul(img.unsqueeze(dim=0), smaps)) # Nc Ny Nx 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(root_sum_of_squares(img, dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create samples with sparse data representation (SparseCartesianDataset)\n",
    "Nc, Ny, Nx, _ = kspace.shape\n",
    "\n",
    "def mask_to_trajectory(mask, Nz, Ny, Nx):\n",
    "    trajectory = mask.clone().type(dtype)\n",
    "    trajectory[..., 0] = 2. * torch.pi / Nz * (-int(Nz/2) + trajectory[..., 0])\n",
    "    trajectory[..., 1] = 2. * torch.pi / Ny * (-int(Ny/2) + trajectory[..., 1]) \n",
    "    trajectory[..., 2] = 2. * torch.pi / Nx * (-int(Nx/2) + trajectory[..., 2]) \n",
    "    return trajectory\n",
    "\n",
    "def extract_kspace_coordinates(kspace, mask): # z coordinate is ignored\n",
    "    Ns, Nl, Nr, _ = mask.shape\n",
    "    Nc, Ny, Nx, _ = kspace.shape\n",
    "    mask_flattened = mask.flatten(end_dim=-2)\n",
    "    return kspace[:, mask_flattened[:,1], mask_flattened[:,2], :].reshape((Ns, Nc, Nl, Nr, 2)) # (Ns=1, Nc, Nl, Nr, 2)\n",
    "\n",
    "\n",
    "# fully sampled frame\n",
    "mask_fully_sampled = torch.stack(torch.meshgrid(torch.tensor([0]), torch.arange(Ny), torch.arange(Nx)), dim=-1) # (Ns=1, Nl=Ny, Nr=Nx, 3)\n",
    "trajectory_fully_sampled = mask_to_trajectory(mask_fully_sampled, 1, Ny, Nx)\n",
    "kspace_fully_sampled = extract_kspace_coordinates(kspace, mask_fully_sampled)\n",
    "\n",
    "sample_fully_sampled = {\n",
    "    \"kspace\": kspace_fully_sampled,\n",
    "    \"trajectory\": trajectory_fully_sampled,\n",
    "    \"mask\": mask_fully_sampled,\n",
    "    \"t_k\": 0.\n",
    "}\n",
    "sample_fully_sampled = copySampleToGPU(sample_fully_sampled)\n",
    "\n",
    "# sub-sampled frame with the FB pattern\n",
    "dataset_info = datasets_cava_v1[10]\n",
    "dataset_fb = CartesianDataset.from_sparse_matfile2d(dataset_info[\"matfile_path\"], dataset_info[\"listfile_path\"], remove_padding=True)\n",
    "ky_sampling_pattern = torch.nonzero(dataset_fb.mask[0, 0, :, int(dataset_fb.Nx/2)]).flatten()\n",
    "\n",
    "num_lines = ky_sampling_pattern.numel()\n",
    "mask_subsampled = torch.stack(torch.meshgrid(torch.tensor([0]), ky_sampling_pattern, torch.arange(Nx)), dim=-1) # (Ns=1, Nl=num_lines, Nr=Nx, 3)\n",
    "trajectory_subsampled = mask_to_trajectory(mask_subsampled, 1, Ny, Nx) # (Ns=1, Nl=num_lines, Nr=Nx, 3)\n",
    "kspace_subsampled = extract_kspace_coordinates(kspace, mask_subsampled)\n",
    "\n",
    "sample_subsampled = {\n",
    "    \"kspace\": kspace_subsampled,\n",
    "    \"trajectory\": trajectory_subsampled,\n",
    "    \"mask\": mask_subsampled,\n",
    "    \"t_k\": 0.\n",
    "}\n",
    "sample_subsampled = copySampleToGPU(sample_subsampled)\n",
    "\n",
    "\n",
    "sample = sample_subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sxs = [1e0, 3e0, 1e1, 3e1, 1e2]\n",
    "out_scales = [30., 100., 300., 1000., 3000.]\n",
    "\n",
    "final_losses = torch.zeros(len(sxs), len(out_scales))\n",
    "mses = torch.zeros(len(sxs), len(out_scales))\n",
    "vifs = torch.zeros(len(sxs), len(out_scales))\n",
    "ssims = torch.zeros(len(sxs), len(out_scales))\n",
    "total_num_epochs = torch.zeros(len(sxs), len(out_scales))\n",
    "\n",
    "metrics = PerformanceMetrics(ser=False, brisque=False, crossection_vif=False, hfen=False, mse=False)\n",
    "\n",
    "for p1, sx in enumerate(sxs): # \n",
    "    for p2, out_scale in enumerate(out_scales): #\n",
    "\n",
    "        # initialize an FMLP for the phantom dataset\n",
    "        param = SimpleNamespace()\n",
    "        param.data  = SimpleNamespace()\n",
    "        param.fmlp = SimpleNamespace()\n",
    "        param.optimizer = SimpleNamespace()\n",
    "        param.hp = SimpleNamespace()\n",
    "\n",
    "        param.data.dataset_type = \"sparse_cartesian\"\n",
    "        param.data.Nc, param.data.Ny, param.data.Nx, _ = kspace.shape\n",
    "\n",
    "        # FMLP parameters\n",
    "        param.fmlp.spatial_in_features = 2\n",
    "        param.fmlp.spatial_fmap_width = 512\n",
    "        param.fmlp.spatial_coordinate_scales = [sx, sx] # kspace coordinate scales in [1/rad]\n",
    "                    \n",
    "        param.fmlp.temporal_in_features = 1\n",
    "        param.fmlp.temporal_fmap_width = 128\n",
    "        param.fmlp.temporal_coordinate_scales = [1.] # temporal coordinate scale in [1/s]\n",
    "\n",
    "        param.fmlp.mlp_width = 512\n",
    "        param.fmlp.mlp_sigma = 0.01\n",
    "        param.fmlp.mlp_scale = 1.\n",
    "        param.fmlp.mlp_hidden_layers = 7\n",
    "        param.fmlp.mlp_hidden_bias = True\n",
    "\n",
    "        param.fmlp.mlp_out_features = 2 * param.data.Nc\n",
    "        param.fmlp.mlp_final_sigma = 0.01\n",
    "        param.fmlp.mlp_final_bias = True\n",
    "\n",
    "        param.fmlp.out_scale = out_scale\n",
    "\n",
    "        ## optimizer parameters\n",
    "        param.optimizer.weight_decay = 0\n",
    "        param.optimizer.lr = 2e-4\n",
    "\n",
    "        param.hp.epsilon = 0.\n",
    "        param.hp.num_epochs_after_last_highscore = 500\n",
    "        param.hp.epsilon = 1e2\n",
    "        param.hp.sigma = 1.\n",
    "        param.hp.lambda_denoising_loss = 0.\n",
    "        param.hp.loss_type = \"l2\"\n",
    "\n",
    "        models = import_file(\"src/models/kspace-fmlp.py\")\n",
    "        model = models.ReconstructionMethod(param)\n",
    "        model.compute_weighted_smaps(smaps.type(dtype), eps=7e0)\n",
    "\n",
    "        run_name = \"sx {}, out_scale {}, eps {}, sigma {}, lambda {}\".format(sx, out_scale, param.hp.epsilon, param.hp.sigma, param.hp.lambda_denoising_loss)\n",
    "\n",
    "        base_dir = \"results/cava_v1_static/10/subsampled_single_frame/KFMLP/l2, normalize, max_vif 2/\"\n",
    "        result_dir = os.path.join(base_dir, run_name)\n",
    "        create_dir(result_dir)\n",
    "        torch.save(param, os.path.join(result_dir, \"param.pth\"))\n",
    "\n",
    "\n",
    "        def plot_reconstruction(ax):\n",
    "            vmax = float(torch.max(root_sum_of_squares(img, dim=-1)).cpu().numpy())*1.1\n",
    "            img_hat = model.evaluate_npy(sample_fully_sampled)\n",
    "            ax.imshow(img_hat, cmap=\"gray\", vmax=vmax)\n",
    "            \n",
    "        def plot_kspace_line(ax):\n",
    "            c = 0\n",
    "            kx = int(Nx/2)\n",
    "            kspace_line = sample_fully_sampled[\"kspace\"][0,:,:,kx:kx+1,:]\n",
    "            kspace_line_hat = model.evaluate_trajectory(sample_fully_sampled[\"trajectory\"][0:1,:,kx:kx+1,:], 0.)[0]\n",
    "\n",
    "            ax.plot(root_sum_of_squares(kspace_line[c,:,0,:], dim=-1).detach().cpu().numpy().flatten())\n",
    "            ax.plot(root_sum_of_squares(kspace_line_hat[c,:,0,:], dim=-1).detach().cpu().numpy().flatten())\n",
    "            ax.set_aspect(0.1)\n",
    "\n",
    "\n",
    "        ## Fit the FMLP to k-space data in sample\n",
    "\n",
    "        writer = SummaryWriter(log_dir=result_dir)\n",
    "\n",
    "        min_loss = float(\"inf\")\n",
    "        min_mse = float(\"inf\")\n",
    "        max_ssim = 0.\n",
    "        max_vif = 0.\n",
    "\n",
    "        num_epochs = 1\n",
    "\n",
    "        i = 0\n",
    "        while i < num_epochs: # iterate over epochs\n",
    "            model.optimizer.zero_grad()\n",
    "            \n",
    "            kspace_hat = model.evaluate_trajectory(sample[\"trajectory\"], sample[\"t_k\"])\n",
    "            if param.hp.loss_type == \"l2\":\n",
    "                reconstruction_loss = model.reconstruction_loss(kspace_hat, sample)\n",
    "            else:\n",
    "                reconstruction_loss = model.high_dynamic_range_loss(kspace_hat, sample, param.hp.epsilon)\n",
    "\n",
    "            denoising_loss = torch.tensor(0.).type(dtype)\n",
    "            if param.hp.lambda_denoising_loss > 0.:\n",
    "                denoising_loss = model.denoising_loss(kspace_hat, sample[\"trajectory\"], sigma=param.hp.sigma, epsilon=param.hp.epsilon)\n",
    "\n",
    "            loss = reconstruction_loss + param.hp.lambda_denoising_loss * denoising_loss\n",
    "\n",
    "            # compute metrics\n",
    "            kspace_hat_fully_sampled = model.evaluate_trajectory(sample_fully_sampled[\"trajectory\"], sample_fully_sampled[\"t_k\"])\n",
    "            squared_error_kspace = model.reconstruction_loss(kspace_hat_fully_sampled, sample_fully_sampled)\n",
    "            img_hat = root_sum_of_squares(model.combine_coils(kspace_hat_fully_sampled), dim=-1).detach().cpu().squeeze()\n",
    "            ref_img = root_sum_of_squares(img.squeeze(), dim=-1)\n",
    "            ssim = metrics.ssim(img_hat, ref_img)\n",
    "            vif = metrics.vif(img_hat, ref_img)\n",
    "            mse = metrics.mse(img_hat, ref_img)\n",
    "\n",
    "            writer.add_scalar(\"training/reconstruction_loss\", denoising_loss, i)\n",
    "            writer.add_scalar(\"training/reconstruction_loss\", reconstruction_loss, i)\n",
    "            writer.add_scalar(\"training/loss\", loss, i)\n",
    "            writer.add_scalar(\"metrics/ssim\", ssim, i)\n",
    "            writer.add_scalar(\"metrics/vif\", vif, i)\n",
    "            writer.add_scalar(\"metrics/mse\", mse, i)\n",
    "\n",
    "            loss.backward()\n",
    "            model.optimizer.step()\n",
    "\n",
    "            if vif > max_vif: # extend the training to param.hp.num_epochs_after_last_highscore epochs after the new VIF highscore\n",
    "                num_epochs = max(num_epochs, i + param.hp.num_epochs_after_last_highscore)\n",
    "                # save model parameters\n",
    "                model.save_state(path=os.path.join(result_dir, \"model_max_vif.pth\"))\n",
    "\n",
    "            min_loss = min(float(loss.detach().cpu()), min_loss)\n",
    "            min_mse = min(float(mse), min_mse)\n",
    "            max_ssim = max(float(ssim), max_ssim)\n",
    "            max_vif = max(float(vif), max_vif)\n",
    "\n",
    "            if i%500 == 0:\n",
    "                fig = plt.figure(figsize = (7,7))\n",
    "                plot_reconstruction(fig.add_subplot(121))\n",
    "                plot_kspace_line(fig.add_subplot(122))\n",
    "                writer.add_figure(\"reconstruction\", fig, i)\n",
    "\n",
    "            if i%10 == 0:\n",
    "                print(\"Iteration {}: Train loss {:.7f}\".format(i, float(loss.detach().cpu())), '\\r', end='')\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        final_losses[p1, p2] = min_loss\n",
    "        mses[p1, p2] = min_mse\n",
    "        vifs[p1, p2] = max_vif\n",
    "        ssims[p1, p2] = max_ssim\n",
    "        total_num_epochs[p1, p2] = num_epochs\n",
    "\n",
    "        model.load_state(path=os.path.join(result_dir, \"model_max_vif.pth\"), gpu=gpu)\n",
    "        fig = plt.figure(figsize = (7,7))\n",
    "        plot_reconstruction(fig.add_subplot(121))\n",
    "        plot_kspace_line(fig.add_subplot(122))\n",
    "        tikzplotlib.save(os.path.join(result_dir, \"max_vif_image_ksp.tex\"), fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_losses, \"finallosses.pth\")\n",
    "torch.save(vifs, \"vifs.pth\")\n",
    "torch.save(ssims, \"ssims.pth\")\n",
    "torch.save(mses, \"mses.pth\")\n",
    "torch.save(total_num_epochs, \"numepochs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_search(values, vx, vy, ylabel, fig_name):\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.semilogx(vx, values)\n",
    "    ax.legend(vy)\n",
    "    ax.set_xlabel(\"sx\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "    fig.savefig(os.path.join(base_dir, fig_name+\".png\"))\n",
    "    tikzplotlib.save(os.path.join(base_dir, fig_name+\".tex\"), fig)\n",
    "\n",
    "plot_grid_search(final_losses, sxs, out_scales, \"loss\", \"grid_search_sx_out_scale_loss\")\n",
    "plot_grid_search(mses, sxs, out_scales, \"mse\", \"grid_search_sx_out_scale_mse\")\n",
    "plot_grid_search(ssims, sxs, out_scales, \"ssim\", \"grid_search_sx_out_scale_ssim\")\n",
    "plot_grid_search(vifs, sxs, out_scales, \"vif\", \"grid_search_sx_out_scale_vif\")\n",
    "plot_grid_search(total_num_epochs, sxs, vifs, \"number of epochs\", \"grid_search_sx_out_scale_num_epochs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
